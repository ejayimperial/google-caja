#!/usr/bin/python

r"""
The state transition file has the lexical grammar:
  comment         =~   /#.*/
  string          =~   /'(?:[^'\\]|\\.)*'|"(?:[^"\\]|\\.)*"/
  char_set        =~   /\[(?:[^\]\\]|\\.)*\]/
  word            =~   /\w+/
  annotation      =~   /@\w+/
  punctuation     =~   /[\(\):,]/
  indent          =~   /^\s+/m

Lines are processed python style where indents on lines that contain
non whitespace or non comment tokens produce the pseudo-token '\n++'
and dedents produce the pseudo-token '\n--'.

and the grammar
  fsm            ::==  <statement>*
  statement      ::==  <alias>
                    |  <var_decl>
                    |  <state_decl>
                    |  <function>
                    |  <template>
  ident          ::==  <word>
  alias          ::==  'alias' <ident> ':' <char_set>
  var_decl       ::==  'var' <ident>: '\n++' <var_values> '\n--'
  var_values     ::==  <var_value> <var_values>?
  var_value      ::==  <char>
                    |  'union' <ident> ':' '\n++' <chars> '\n--'
  chars          ::==  <char> (',' <chars>)?
  state_decl     ::==  <annotation>* <ident> ':' '\n++' ( <transition>)* '\n--'
  transition     ::==  <indent> <start_state> <result>
  result         ::==  ':' <target> <side_effect>*
                    |  as <target> <side_effect>*
                    |  ',' 'gosub' <target>
                    |  ',' 'return'
                    |  'error' <error_message>?
  start_state    ::==  <pattern>
                    |  'else'
  pattern        ::==  <pattern_atom> (',' <pattern>)*
  pattern_atom   ::==  <ident>  # matches Alias above
                    |  <char>  # string with exactly one inner match
  target         ::==  <state_name>
                    |  <function_name>
  error_message  ::== '(' <string> ')'
  actuals        ::==  <actual> (',' <actuals>)?
  actual         ::==  <ident>
                    |  <string>
  side_effect    ::==  ',' 'store'      '(' <var_name> ',' <modifiers> ')'
                    |  ',' 'record'     '(' <var_name> ')'
                    |  ',' 'set'        '(' <var_name> ',' <string> ')'
                    |  ',' 'clear'      '(' <var_name> ')'
                    |  ',' 'decode'     '(' <var_name> ',' <extern_name> ')'
  modifiers      ::==  '\''<modifier>*'\''  
  modifier       ::==  'i'  # case insensitive
                    |  '?'  # set if not null
  function       ::==  'def' <function_name> '(' <var_name> ')'
                       '\n++' <fn_transition>* '\n--'
  fn_transition  ::==  <indent> <fn_pattern> <result>
                    |  'else' <result>
  fn_pattern     ::==  fn_pattern_part (',' fn_pattern)?
  fn_pattern_pt  ::==  <string>
                    |  <var_name>
  template       ::==  'template' <ident> ':' '\n++' <member_def>* '\n--'
  namespace      ::==  'namespace' <prefix> ':' '\n++' <namespace_body> '\n--'
  namespace_body ::==  <overrides> <instantiation>* <member_def>*
  overrides      ::==  '*' ':' '\n++' <transition>* '\n--'
  instantiation  ::--  '<' <template_name> '>'
  member_def     ::==  <state_decl>
                    |  <function>
"""

import re
import state_machine
import sys
import types

class Token(object):
  def __init__(self, text, line_no):
    self.text = text
    self.line_no = line_no

  def __str__(self):
    return 'Token(text=%r, line_no=%r)' % (self.text, self.line_no)


class TokenQueue(object):
  def __init__(self, tokens):
    assert reduce(lambda a, b: isinstance(b, Token) and a, tokens, True)
    self.tokens = tokens
    self.pos = 0

  def is_empty(self):
    return self.pos >= len(self.tokens)

  def peek(self):
    return self.tokens[self.pos]

  def advance(self):
    self.pos += 1

  def pop(self):
    tok = self.tokens[self.pos]
    self.pos += 1
    return tok

  def check(self, text):
    if not self.is_empty() and text == self.peek().text:
      self.advance()
      return True
    return False

  def expect(self, text):
    if self.is_empty():
      raise Exception('Expected %r but saw EOF' % text)
    tok = self.peek()
    if tok.text != text:
      raise Exception('Expected %r but was %r at %s' % (
          text, tok.text, tok.line_no))
    self.advance()
    return tok


INDENT_PSEUDO_TOKEN = '\n++'
DEDENT_PSEUDO_TOKEN = '\n--'

def lex(fsm_source, line_no=1):
  pattern = re.compile(
      r'^(?:(?:'  # Pseudo indent tokens generated by examining group 1.
      r'[\r\n]+([ \t]*)(?=[^\s#])'  # indentation is significant
      r')|('  # Real tokens are stored in group 2.
      r'\'(?:[^\'\\]|\\.)*\''  # singly quoted strings
      r'|\"(?:[^\"\\]|\\.)*\"'  # double quoted strings
      r'|\[(?:[^\]\\]|\\.)*\]'  # square bracketed character sets
      r'|\w+'  # identifiers
      r'|@\w+'  # annotations
      r'|[\(\):,\*<>])'  # single punctuation characters
      r')|(?:'  # Ignorable tokens not captured in any group.
      r'#.*'  # comments
      r'|[\r\n]+'  # ignorable newlines
      r'|[ \t]+'  # ignorable whitespace
      r')')
  indent_stack = [0]

  def count_newlines(s):
    n = 0
    for ch in s:
      if ch == '\n': n += 1
    return n
  while fsm_source:
    m = pattern.search(fsm_source)
    if m is None:
      raise Exception('Syntax error in %r at line %s' % (
          len(fsm_source > 20) and '%s...' % fsm_source[0:20] or fsm_source,
          line_no))
    token = m.group(0)
    fsm_source = fsm_source[m.end(0):]
    if m.group(2) is not None:  # a normal token
      yield Token(token, line_no)

    line_no += count_newlines(token)

    if m.group(1) is not None:  # check leading whitespace for indent or dedent
      indentation = reduce(
          lambda a, b: a + (b == '\t' and (8 - (a & 7)) or 1), m.group(1), 0)
      if indentation != indent_stack[-1]:
        if indentation > indent_stack[-1]:
          indent_stack.append(indentation)
          yield Token(INDENT_PSEUDO_TOKEN, line_no)
        else:
          while indent_stack[-1] > indentation:
            del indent_stack[-1:]
            yield Token(DEDENT_PSEUDO_TOKEN, line_no)
          if indent_stack[-1] != indentation:
            raise 'indentation at line %s does not match previous' % line_no
  while len(indent_stack) > 1:
    yield Token(DEDENT_PSEUDO_TOKEN, line_no)
    del indent_stack[-1:]

def parse(tq):
  fsm = state_machine.StateMachine()
  while not tq.is_empty():
    _parse_statement(tq, fsm)
  return fsm

def _parse_statement(tq, fsm):
  annotations = _parse_annotations(tq)
  tok = tq.peek()
  if len(annotations) == 0:
    if tok.text == 'alias':
      _parse_alias(tq, fsm)
      return
    elif tok.text == 'template':
      _parse_template(tq, fsm)
      return
    elif tok.text == 'namespace':
      _parse_namespace(tq, fsm)
      return
  if tok.text == 'var':
    _parse_var_decl(annotations, tq, fsm)
  elif tok.text == 'def':
    _parse_function_decl(annotations, tq, fsm)
  else:
    _parse_state_decl(annotations, tq, fsm)

def _parse_alias(tq, fsm):
  alias_tok = tq.expect('alias')
  alias_name = _parse_ident(tq)
  tq.expect(':')
  chars = _parse_char_set(tq)
  if alias_name in fsm.aliases:
    raise Exception('alias %s multiply declared at %s'
        % (alias_name, alias_tok.line_no))
  fsm.aliases[alias_name] = state_machine.Alias(alias_name, chars)

def _parse_ident(tq):
  if tq.is_empty(): tq.expect('<ident>')
  tok = tq.pop()
  if re.match('^\w+$', tok.text) is None:
    raise Exception('expected identifier not %s at %s'
                    % (tok.text, tok.line_no))
  return state_machine.Identifier(tok.text, tok.line_no)

def _decode_string(s, line_no):
  out = []
  while s:
    ch, s = _decode_one_char(s, line_no)
    out.append(ch)
  return ''.join(out)

def _decode_char(s, line_no):
  ch, s = _decode_one_char(s, line_no)
  if s != '':
    raise Exception('Character literal with unused data %r at line %s'
        % (s, line_no))
  return ch

def _parse_string(tq):
  tok = tq.pop()
  if tok.text[0] not in ('\'', '"'):
    raise Exception('expected literal string not %r at line %s'
        % (tok.text, tok.line_no))
  return _decode_string(tok.text[1:-1], tok.line_no)

def _parse_char_set(tq):
  tok = tq.pop()
  if not tok.text.startswith('['):
    raise Exception('expected character set not %s at %s'
                    % (tok.text, tok.line_no))
  chars = []
  ranges = tok.text[1:-1]
  while ranges:
    char0, ranges = _decode_one_char(ranges, tok.line_no)
    if ranges.startswith('-'):
      char1, ranges = _decode_one_char(ranges[1:], tok.line_no)
    else:
      char1 = char0
    if char1 < char0:
      raise Exception('charset at %s is out of order: %r > %r'
                      % (tok.line_no, char0, char1))
    if char1 != char0:
      start, end = ord(char0), ord(char1)
      for i in xrange(start, end + 1):
        if end >= 0x7f:
          chars.append(unichr(i))
        else:
          chars.append(chr(i))
    else:
      chars.append(char0)
  chars.sort()
  return tuple(set(chars))

_ESCS = { 'b': '\b', 'n': '\n', 'r': '\r', 'f': '\f', 'v': '\v', 't': '\t' }
def _decode_one_char(s, line_no):
  m = re.match(r'(?:\\u([0-9a-fA-F]{4})|\\(.)|([^\\]))', s)
  if not m:
    raise Exception('malformed escape sequence %r at line %s' % (s, line_no))
  if m.group(1) is not None:
    codepoint = int(m.group(1), 16)
    ch = unichr(codepoint)
  elif m.group(2) is not None:
    ch = m.group(2)
    if ch in _ESCS: ch = _ESCS[ch]
  else:
    ch = m.group(3)
  return ch, s[m.end(0):]

def _parse_var_decl(annotations, tq, fsm):
  def_tok = tq.pop()
  name = _parse_ident(tq)
  values = []

  tq.expect(':')
  tq.expect(INDENT_PSEUDO_TOKEN)
  while True:
    if tq.check('union'):
      union_name = _parse_ident(tq)
      union_values = []
      tq.expect(':')
      tq.expect(INDENT_PSEUDO_TOKEN)
      while True:
        union_values.append(_parse_string(tq))
        if tq.check(DEDENT_PSEUDO_TOKEN):
          break
        tq.expect(',')
      values.append(state_machine.UnionVarValue(union_name, union_values))
    else:
      values.append(state_machine.SingleVarValue(_parse_string(tq)))

    if tq.check(DEDENT_PSEUDO_TOKEN):
      break
  fsm.var_decls[name] = state_machine.VarDecl(annotations, name, values)

def _parse_function_decl(annotations, tq, fsm):
  def_tok = tq.peek()
  fn = _parse_function(annotations, tq)
  if fn.name in fsm.functions:
    raise Exception('function %s multiply declared at %s'
        % (fn.name, def_tok.line_no))
  fsm.functions[fn.name] = fn

def _parse_function(annotations, tq):
  tq.expect('def')
  name = _parse_ident(tq)
  tq.expect('(')
  var_name = _parse_ident(tq)
  tq.expect(')')
  tq.expect(':')
  fn = state_machine.Function(annotations, name, var_name)
  tq.expect(INDENT_PSEUDO_TOKEN)
  while not tq.check(DEDENT_PSEUDO_TOKEN):
    fn.transitions.append(_parse_fn_transition(tq))
  return fn

def _parse_template(tq, fsm):
  template_tok = tq.peek()
  tq.expect('template')
  name = _parse_ident(tq)
  if name in fsm.templates:
    raise Exception('template %s multiply defined at line %s'
        % (name, template_tok.line_no))
  tq.expect(':')
  tq.expect(INDENT_PSEUDO_TOKEN)
  members = []
  while not tq.check(DEDENT_PSEUDO_TOKEN):
    members.append(_parse_member_definition(tq))
  fsm.templates[name] = state_machine.Template(name, members)

def _parse_namespace(tq, fsm):
  namespace_tok = tq.peek()
  tq.expect('namespace')
  prefix = _parse_ident(tq).text
  if prefix in fsm.namespaces:
    raise Exception('namespace %s multiply defined at line %s'
        % (prefix, namespace_tok.line_no))
  tq.expect(':')
  tq.expect(INDENT_PSEUDO_TOKEN)
  overrides = []
  tq.expect('*')
  tq.expect(':')
  tq.expect(INDENT_PSEUDO_TOKEN)
  while not tq.check(DEDENT_PSEUDO_TOKEN):
    overrides.append(_parse_transition(tq))
  instantiations = []
  while tq.check('<'):
    instantiations.append(_parse_ident(tq))
    tq.expect('>')
  members = []
  while not tq.check(DEDENT_PSEUDO_TOKEN):
    members.append(_parse_member_definition(tq))
  fsm.namespaces[prefix] = state_machine.Namespace(
      prefix, overrides, instantiations, members)

def _parse_member_definition(tq):
  annotations = _parse_annotations(tq)
  if tq.peek().text == 'def':
    return _parse_function(annotations, tq)
  else:
    return _parse_state(annotations, tq)

def _parse_annotations(tq):
  tok = tq.peek()
  if not tok.text.startswith('@'):
    return ()
  annotations = [tok.text]
  while True:
    tq.advance()
    tok = tq.peek()
    if not tok.text.startswith('@'):
      break
    annotations.append(tok.text)
  return annotations

def _parse_state_decl(annotations, tq, fsm):
  tok = tq.peek()
  state = _parse_state(annotations, tq)
  if state.name in fsm.states:
    raise Exception('state %s multiply declared at %s'
        % (state.name, tok.line_no))
  fsm.states[state.name] = state

def _parse_state(annotations, tq):
  name = _parse_ident(tq)
  tq.expect(':')
  state = state_machine.State(annotations, name)
  tq.expect(INDENT_PSEUDO_TOKEN)
  while not tq.check(DEDENT_PSEUDO_TOKEN):
    state.transitions.append(_parse_transition(tq))
  return state

def _parse_fn_transition(tq):
  if tq.check('else'):
    return state_machine.ElseTransition(_parse_result(tq))

  return state_machine.FunctionTransition(
      _parse_fn_patterns(tq), _parse_result(tq))

def _parse_fn_patterns(tq):
  patterns = []
  while True:
    tok = tq.peek()
    if tok.text[0] in ('\'', '"'):
      literal = _decode_string(tok.text[1:-1], tok.line_no)
      tq.advance()
      patterns.append(state_machine.StringPattern(literal))
    else:
      patterns.append(state_machine.VariablePattern(_parse_ident(tq)))
    if not tq.check(','): break
    tq.check('\n  ')
  return patterns

def _parse_transition(tq):
  if tq.check('else'):
    return state_machine.ElseTransition(_parse_result(tq))

  patterns = []
  while 1:
    tok = tq.peek()
    if tok.text[0] == '\'':
      patterns.append(
          state_machine.CharPattern(_decode_char(tok.text[1:-1], tok.line_no)))
      tq.advance()
    else:
      patterns.append(state_machine.CharSetPattern(_parse_ident(tq)))
    if not tq.check(','): break

  return state_machine.PatternTransition(patterns, _parse_result(tq))

def _parse_result(tq):
  if tq.check('as'):
    is_reference = True
  else:
    tq.expect(':')
    is_reference = False
  target_name = _parse_ident(tq)

  if target_name.text in ('error', 'gosub', 'return'):
    if is_reference:
       raise Exception('expected state or function name, not %r at line %s'
           % (target_name, target_tok.line_no))

    if target_name.text == 'error':
      if tq.check('('):
        message = _parse_string(tq)
        tq.expect(')')
      else:
        message = None
      return state_machine.ErrorResult(message)
    elif target_name.text == 'gosub':
      target_name = _parse_ident(tq)
      return state_machine.GoSubResult(target_name, _parse_side_effects(tq))
    elif target_name.text == 'return':
      return state_machine.ReturnResult(_parse_side_effects(tq))

  side_effects = _parse_side_effects(tq)
  if is_reference:
    return state_machine.ReferenceResult(target_name, side_effects)
  else:
    return state_machine.TransitionResult(target_name, side_effects)

def _parse_side_effects(tq):
  side_effects = []
  while tq.check(','):
    side_effects.append(_parse_side_effect(tq))
  return side_effects

def _parse_side_effect(tq):
  tok = tq.peek()
  effect = _parse_ident(tq).text
  if effect not in ('record', 'store', 'set', 'clear', 'decode'):
    raise Exception('unknown side effect %s at line %s', (effect, tok.line_no))
  tq.expect('(')
  params = [_parse_ident(tq)]
  if effect == 'set':
    tq.expect(',')
    params.append(_parse_string(tq))
  elif effect == 'store':
    tq.expect(',')
    modifiers_tok = tq.peek()
    modifiers = _parse_string(tq)
    for ch in modifiers:
      if ch not in ('', 'i', '?'):
        raise Exception('unrecognized modifier %r to store at line %s'
            % (ch, modifiers_tok.line_no))
    params.append(modifiers)
  elif effect == 'decode':
    tq.expect(',')
    external_function_name = _parse_string(tq)
    params.append(external_function_name)
  tq.expect(')')
  return state_machine.SideEffect(effect, params)
